{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 11 -  Final Assignment\n",
    "\n",
    "**_Author: Jessica Cervi_**\n",
    "\n",
    "**Expected time = 3.5 hours**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment overview\n",
    "\n",
    "Welcome to the final assignment of this course! At this point, you have learnt about different machine learning algorithms and you have applied each of them to different problems. In this assignment, we will instead use one single data set and try make a prediction by using different algorithms with the goal of deciding which one performs the best.\n",
    "\n",
    "After reading the data set, we will perfom some exploratory data analysis to undertand the relationship between some of the features in the data set. Next, we will extensively manipulate the dataframe to prepare our data for our analysis. We will do so by using techniques such as label encoding, one hot encoding and correlation. Finally, we will apply three different machine learning algorithms to solve our problem.\n",
    "\n",
    "This assignment is designed to help you apply the machine learning algorithms you have learned using packages in Python. Python concepts, instructions, and a starter code are embedded within this Jupyter Notebook to help guide you as you progress through the assignment. Remember to run the code of each code cell prior to submitting the assignment. Upon completing the assignment, we encourage you to compare your work against the solution file to perform a self-assessment.\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "\n",
    "\n",
    "- Define the hypothesis to be tested and prediction to be made\n",
    "- Present the approaches used in the analysis\n",
    "- Discuss the results obtained using different algorithms\n",
    "- Discuss the strengths and limitations of each analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index:\n",
    "\n",
    "#### Week 11: final assignment\n",
    "\n",
    "\n",
    "- [Part 1](#part1)- Importing the data set\n",
    "- [Part 2](#part2)- Exploratory data analysis (EDA)\n",
    "- [Part 3](#part3) -  Preparing our data\n",
    "- [Part 4](#part4) -  Correlation\n",
    "- [Part 5](#part5) -  Splitting our data for modelling\n",
    "- [Part 6](#part6) -  Decision tree model (reservation_status included)\n",
    "- [Part 7](#part7) -  Decision tree model (reservation_status excluded)\n",
    "- [Part 8](#part8) -  K-nearest neighbours\n",
    "- [Part 9](#part9) -  Naïve Bayes\n",
    "- [Part 10](#part10) -  Conclusion\n",
    "\n",
    "\n",
    "## Final assignment\n",
    "\n",
    "In the past weeks, we have learnt about different machine mearning algorithms that allowed us to analyse and make predictions on different data sets.\n",
    "\n",
    "Now that we have come to end of this course, it is time to compare the performances of some of these algorithms, analyse the results, and discuss the strengths and limitations of each of them.\n",
    "\n",
    "The data set that we will be using in this assignment contains booking information for a city hotel and a resort hotel, and includes information such as when the booking was made, length of stay, the number of adults, children, and/or babies, and the number of available parking spaces, among other things. You can find more information about the data set [here](https://www.kaggle.com/jessemostipak/hotel-booking-demand).\n",
    "\n",
    "The aim is to create meaningful estimators from the data set we have and to select the model that predicts the cancellation best by comparing them with the accuracy scores of different machine learning models. \n",
    "\n",
    "As you can imagine, the cancellation rate for bookings in the online booking industry is quite high. Once the reservation has been cancelled, there is almost nothing to be done. This may creates discomfort for many hotels and thus creates a necessity to take precautions. Therefore, predicting reservations that can be cancelled and preventing these cancellations can create a positive value for the hotels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part1'></a>\n",
    "\n",
    "### Part 1 -  Importing the data set\n",
    "\n",
    "As usual, we will begin this assignment by importing the necessary libraries and the data set.\n",
    "\n",
    "Run the code cell below to import some of the libraries that we will need throughout this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will then use `pandas` to import the data set. Complete the code cell below by adding the name of the dataset, \"hotel_bookings.csv\" as a `str` to `.read_csv()`. Assign the dataframe to the variable `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Before building any machine learning algorithms, we should explore the data.\n",
    "\n",
    "We begin by visualizing the first ten rows of the DataFrame `df` using the function `.head()`. By default, `.head()` displays the first five rows of a DataFrame.\n",
    "\n",
    "Complete the code cell below by passing the desired number of rows as an `int` to the function `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head( )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a description of what some of the features in the dataframe above represent:\n",
    "\n",
    "- `hotelHotel` (H1 = Resort Hotel or H2 = City Hotel)\n",
    "- `is_canceled`: value indicating if the booking was canceled (1) or not (0)\n",
    "- `lead_time`: number of days that elapsed between the entering date of the booking into the PMS and the arrival date\n",
    "- `stays_in_weekend_nights`: number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel\n",
    "- `stays_in_week_nights`: number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel\n",
    "- `previous_cancellations`: number of previous bookings that were cancelled by the customer prior to the current booking\n",
    "- `previous_bookings_not_canceled`: number of previous bookings not cancelled by the customer prior to the current booking\n",
    "- `booking_changes`: number of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation\n",
    "- `deposit_type`: indication if the customer made a deposit to guarantee the booking. This variable can assume three categories: \n",
    "    - No Deposit – no deposit was made\n",
    "    - Non Refund – a deposit was made in the value of the total stay cost\n",
    "    - Refundable – a deposit was made with a value under the total cost of stay\n",
    "- `market_segment`: market segment designation. In categories, the term “TA” means “Travel Agents” and “TO” means “Tour Operators”.\n",
    "- `Type of booking`, assuming one of four categories:\n",
    "    - Contract - when the booking has an allotment or another type of contract associated to it; \n",
    "    - Group – when the booking is associated to a group\n",
    "    - Transient – when the booking is not part of a group or contract, and is not associated to another transient booking\n",
    "    - Transient-party – when the booking is transient, but is associated to at least one other transient booking\n",
    "- `reservation_status_date`: date at which the last status was set. \n",
    "- `reservation_status`: status to understand when the booking was canceled or when the customer checked-out of the hotel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it is always useful to get a sense of how many missing values there are in a dataframe.\n",
    "\n",
    "Run the code cell below to print the number of NaN's for each colum in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of NaN in each columns:\", df.isnull().sum(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part2'></a>\n",
    "\n",
    "### Part 2 -  Exploratory data analysis (EDA)\n",
    "\n",
    "To make sure we consider all the correct features to make an accurate prediction, it may be useful to create some plots to have a better understanding of our data.\n",
    "\n",
    "**Note:** In this part of the assignment, we will be using the Python data visualisation library `seaborn`. Links to the documentation of each function used in this part will be given below.\n",
    "\n",
    "\n",
    "We could begin by visualising the number of cancellations by repeated guests. A good approach to do so is by using a [count plot](https://seaborn.pydata.org/generated/seaborn.countplot.html), or barplot, that shows the counts of observations in each categorical bin using bars.\n",
    "\n",
    "Complete the code in the code cell below by setting the following parameters of the function `countplot()`:\n",
    "- x = \"is_canceled\", \n",
    "- hue = 'is_repeated_guest',\n",
    "- data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot title\n",
    "plt.title(\"Canceled or not\", fontdict = {'fontsize': 15})\n",
    "\n",
    "ax = sns.countplot( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you infer from the figure above?\n",
    "\n",
    "**DOUBLE CLICK ON THIS CELL TO TYPE YOUR ANSWER**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, it may be interesting to look at the distribution of market segments by deposit type.\n",
    "\n",
    "Again, we can use a count plot to visualise this.\n",
    "\n",
    "Complete the code in the code cell below by setting the following parameters of the function `countplot()`:\n",
    "- x = \"market_segment\", \n",
    "- hue = 'deposit_type',\n",
    "- data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot size\n",
    "plt.figure(figsize = (12,8))\n",
    "#plot title\n",
    "plt.title(\"Countplot Distrubiton of Segment by Deposit Type\", fontdict = {'fontsize':15})\n",
    "\n",
    "ax = sns.countplot( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, it may be interesting to look at the distribution of market segments by cancellation.\n",
    "\n",
    "Complete the code in the code cell below by setting the following parameters of the function `countplot()`:\n",
    "- x = \"market_segment\", \n",
    "- hue = 'is_canceled',\n",
    "- data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.title(\"Countplot Distributon of Segments by Cancellation\", fontdict = {'fontsize':15})\n",
    "\n",
    "ax = sns.countplot( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at Offline TA/TO and Groups, the situations where the deposit was received were only in the scenarios where the groups came. It is quite logical to apply a deposit for a large number of customers who will fill important amount of the hotel capacity.\n",
    "\n",
    "As a first thought, we expected the cancellation rate to be lower in the market segments where deposits are applied. But when we look at the cancellations by market segment, it seems that this is not the case. Deposits were applied to Offline TA/TO and Groups reservations, and not for Direct reservations:\n",
    "\n",
    "- Groups segment has a cancellation rate more than 50%.\n",
    "- Offline TA/TO (Travel Agents/Tour Operators) and Online TA has a cancellation rate more than 33%.\n",
    "- Direct segment has a cancellation rate less than 20%.\n",
    "\n",
    "It is surprising that the cancellation rate in the first two segments is high despite the application of a deposit. The fact that cancellations are made collectively, like reservations, may explain this situation a bit.\n",
    "\n",
    "Another insight that looks interesting is that the cancellation rate in the direct segment is very low. We might hypothesise that a mutual trust relationship has been established in the cases where people are communicating one to one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part3'></a>\n",
    "\n",
    "### Part 3 -  Preparing our data\n",
    "    \n",
    "\n",
    "In Part 1, we saw that the columns `Company`, `Agent` and `Country` had missing values. Before deciding whether it is a good idea to drop these columns or keep some of them and try to fill the values using imputation, it is always useful to have an understanding of the percentage of missing values.\n",
    "\n",
    "In the code cell below define a function called `perc_mv`. Your function should take, as input a dataframe `x` and a series `y`. Your function should compute the percentage of missing values in the series `y` by using the formula:\n",
    "\n",
    "$$perc = \\frac{\\sum (\\text{Null values in y})}{\\text{len}(x)}*100$$\n",
    "\n",
    "Your function should return the variable `perc`.\n",
    "\n",
    "**HINT:** You can compute the sum of null values in `y` by using the same code we used in Part 1 to print the number of missing values for each column. Next, you can sum these null values using the function `sum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_mv(x, y):\n",
    "    #compute percentage\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to print the percentange of missing values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing value ratios:\\nCompany: {}\\nAgent: {}\\nCountry: {}\\nChildren: {}'.format(\n",
    "    perc_mv(df, df['company']),\n",
    "    perc_mv(df, df['agent']),\n",
    "    perc_mv(df, df['country']), \n",
    "    perc_mv(df, df['children'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, 94.3% of company column has missing values. Therefore, we do not have enough values to fill the rows of the Company column via any imputation method. The best option is to drop the company column.\n",
    "\n",
    "In the code cell below, use the function `drop()` to drop the column `Company` from the dataframe. Set the argument `axis =1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also four missing values in the `children` column. If there is no information about children, we might infer that those customers do not have any children.\n",
    "\n",
    "Complete the code cell below so to fill the missing values in the column `children` with 0. Use the function `fillna()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['children'] ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we may want to check the features to create some more meaningful variables and reduce the number of features.\n",
    "\n",
    "In the code cell below, use the attribute `dtype` on `df` to retrieve the data type for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use dtype on df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with the column `hotel`. \n",
    "\n",
    "Redefine this column so that it has value 1 if the entry is `Resort Hotel` and value 0 if the entry is `City Hotel`\n",
    "\n",
    "**HINT**: You can accomplish this in a number of ways, such as using a list comprehension and/or by using a lambda function. Here's a pseucode to help you achieve this:\n",
    "\n",
    "```Python\n",
    "df['hotel'] = [1 if x is equal to \"Resort Hotel\"  or 0 otherwise for x in df['hotel']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hotel'] = \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will take of the column `arrival_date_month`.\n",
    "\n",
    "Here, we want to map the name of each month to the corresponding calendar number (January = 1, February  = 2 and so on). Complete the code cell below by filling the remaining months inside the function `map()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete the code cell below\n",
    "df['arrival_date_month'] = df['arrival_date_month'].map({'January':1, })\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try to summarize some features in a smart way.\n",
    "\n",
    "It may be interesting to include in our analysis whether a reservation was made by  a family or not. We don't really have this information yet, but we can assume that if the total number of adults and the number of babies or children are greater than zero then the reservation was made for a family.\n",
    "\n",
    "In the code cell below, complete the definition of the function `family`. This function takes, as input, a dataframe `data` and returns a value `val` defined in the following way:\n",
    "\n",
    "```python\n",
    "def family(data):\n",
    "    if number of adults > 0 and number of children > 0:\n",
    "        val = 1\n",
    "    elif number of adults > 0 and number of babies > 0:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "```\n",
    "\n",
    "Your function should return val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def family(data):\n",
    "    #if number of adults > 0 and number of children > 0:\n",
    "    \n",
    "    val = 1\n",
    "    #elif number of adults > 0 and number of babies > 0:\n",
    "    \n",
    "    val = 1\n",
    "    else:\n",
    "    val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can try to somehow encode some information about the deposit.\n",
    "\n",
    "In the code cell below, complete the definition of the function `deposit` that takes, as input, a dataframe `data`. Your function should return 0 if no deposit was paid or if the deposit type was refundable and 1 otherwise. Note that this information can be extracted from the column `deposit_type`.\n",
    "\n",
    "```python\n",
    "def deposit(data):\n",
    "    if no deposit or refundable deposit:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deposit(data):\n",
    "    #if no deposit or refundable deposit:\n",
    "        \n",
    "        return 0\n",
    "    else:\n",
    "        return 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below we have defined a function `feature()` that takes a dataframe as input and applies the functions defined above to that dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(data):\n",
    "    data[\"is_family\"] = data.apply(family, axis = 1)\n",
    "    data[\"total_customer\"] = data[\"adults\"] + data[\"children\"] + data[\"babies\"]\n",
    "    data[\"deposit_given\"] = data.apply(deposit, axis=1)\n",
    "    data[\"total_nights\"] = data[\"stays_in_weekend_nights\"]+ data[\"stays_in_week_nights\"]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code cell below to apply the function `feature` to our dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to visualise the new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the way we modified our dataframe, some columns like `adults`, `children`, `babies`, `deposit_type` and `reservation_status_update` can be dropped.\n",
    "\n",
    "In the code cell below, use the function `drop()` to eliminate the columns listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part4'></a>\n",
    "\n",
    "### Part 4 - Correlation\n",
    "\n",
    "One way to decide which features are going to be more impactful when running an analysis is to look at the correlation between them.\n",
    "\n",
    "Pearson's correlations are single value numerical summaries that represent the strength and direction of a linear relationship. Correlation values range from -1 to 1. Values further away from 0 represent stronger relationships, and the sign of the correlation (positive or negative) represents the direction of the relationship.  The graphs below depict a visual representation of Pearson correlations.\n",
    "\n",
    "![pearson-1-small.png](pearson-1-small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to copy the data to check the correlation between variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we observe all of our features, we may assume that some, such as `reservation_status` might have a higher correlation to `is_cancelled` than others. We can verify this by using label encoding on `reservation_status` and then compute it's correlation value to `is_cancelled`.\n",
    "\n",
    "Remember, **label encoding** is a popular encoding technique for handling categorical variables. In this technique, each label is assigned a unique integer based on alphabetical ordering. Label encoding can be implemented in Python using the `scikit-learn` library.\n",
    "\n",
    "Complete the code cell below to import `LabelEncoder` from `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use `LabelEncoder()` to define a transform `le`. Finally, use the function `fit_transform()` on the column `reservation_status` to encode the feature as desired. You can find the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "cor_df['reservation_status'] = le.fit_transform(cor_df['reservation_status']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will visualise the correlation between all of the features. \n",
    "\n",
    "In the code cell below, use the function `corr()` on `cor_df` to visualise a table with all the correlation values between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use corr() on cor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we want to try to predict the likelihood of a reservation being cancelled, it is useful to visualise the sorted correlation values for the column `is_canceled`.\n",
    "\n",
    "In the code cell below, select the column `is_canceled` from the correlation table and apply `sort_values()` to visualise the correlation values in a descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the most impactful feature?\n",
    "\n",
    "**DOUBLE CLICK ON THIS CELL TO TYPE YOUR ANSWER**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, we notice that  `arrival_date_week_number`, `stays_in_weekend_nights` and `arrival_date_day_of_month` are not very important when predicting cancellations.\n",
    "\n",
    "Also, in Part 3, we saw we had some missing values in the `agent` column. It is relevant to predicting cancellation but since the missing values are equal to 13% of the total data, it is better to drop that column. Because the different values in this column represent the ID of the travel agency that made the booking, trying to fill this columns may misguide the predictions.\n",
    "\n",
    "In the code cell below, use the function `drop()` to eliminate all of the columns listed above from `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also decide to delete the NA row of the `country` column.\n",
    "\n",
    "Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = df.loc[pd.isna(df[\"country\"]), :].index \n",
    "df = df.drop(df.index[indices])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost ready for modelling! The last thing to do is to make sure that all the variables are converted into a form that could be provided to machine learning algorithms to do a better job in prediction.\n",
    "\n",
    "\n",
    "\n",
    "Sometimes in data sets, we encounter columns that contain numbers of no specific order of preference. The data in the column usually denotes a category or value of the category and also when the data in the column is label encoded. This confuses the machine learning model, to avoid this the data in the column should be one hot encoded.\n",
    "\n",
    "\n",
    "One-hot encoding refers to splitting the column which contains numerical categorical data to many columns depending on the number of categories present in that column. Each column contains “0” or “1” corresponding to the column it has been placed.\n",
    "This process can be done using the `pandas` function `get_dummies()`. (You can find the documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)).\n",
    "\n",
    "\n",
    "\n",
    "In the code cell below, apply the function `get_dummies()` to the columns `meal`, `market_segment`, `distribution_channel`, `reserved_room_type`, `assigned_room_type`, `customer_type`, `reservation_status`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to take care of the column `country`. There are more than 300 classes here, so using label encoding might be more appropriate in this case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `LabelEncoder()` to define a transforme `le`. Finally, use the function `fit_transform()` on the columns `country`  and `reservation_status` to encode the feature as desired. You can find the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = \n",
    "df['country'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part5'></a>\n",
    "\n",
    "### Part 5 -  Splitting our data for modelling\n",
    "\n",
    "In this section, we prepare our `X` dataframe and `y` series, separating the features we intend to use from our outcome variable. \n",
    "\n",
    "Splitting the `X` and the `y` is an important step when pre-processing data. Usually, `X` is our predictors matrix, containing all of the features except for the one we are trying to predict, whereas `y` contains the outcome variable we are interested in.\n",
    "\n",
    "Complete the code cell below to split our data into `X` and `y`. `X` should contain all features except  the outcome variable `is_canceled`. \n",
    "\n",
    "`y` should contain only the outcome variable `is_canceled` as a pandas series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \n",
    "y ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's now perform a standard split into a training and test set. We'll use 70% of our data as a training set, and 30% as a test set.\n",
    "\n",
    "In the code cell below, import the module `train_test_split` from `scikit-learn` and split our `X` and `y` data into training and test sets (`X_train`, `X_test`, `y_train`, `y_test`). Use 30% of the data as a test set, and the remaining 70% for the training set. For reproducibility, set a random state of `42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  import \n",
    "X_train, X_test, y_train, y_test = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part6'></a>\n",
    "\n",
    "### Part 6 - Decision tree model (reservation_status included)\n",
    "\n",
    "\n",
    "Decision trees are a non-parametric supervised learning method used for classification and regression. Decision trees learn from data to approximate a curve with a set of if-then-else decision rules. The deeper the tree, the more complex the decision rules. Decision trees build classification or regression models in the form of trees. \n",
    "\n",
    "\n",
    "In the code cell below, import the `DecisionTreeClassifier` class from `sklearn.tree` and instantiate the class as `cart`. We'll use `max_depth = 12`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from import \n",
    "cart = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, use the `fit()` method to train the model on the training `X` and `y` sets.\n",
    "\n",
    "Finally, predict the test set results from the trained `cart_model` object using `X_test` and save them to `y_pred_cart`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_model = \n",
    "y_pred_cart = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the performance of this model!\n",
    "We can do so by printing the accuracy score, the confusion matrix and the AUC score. Remember:\n",
    "\n",
    "- The *accuracy score* is one metric for evaluating classification models. Informally, accuracy is the fraction of predictions our model got right. Formally, accuracy has the following definition:\n",
    "\n",
    "$$\\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}} = \\frac{\\text{TP} +\\text{TN}}{\\text{TP} +\\text{TN}+\\text{FP} +\\text{FN}}$$\n",
    "\n",
    "- The *confusion matrix* is a summary of prediction results on a classification problem. The number of correct and incorrect predictions are summarised with count values and broken down by each class. This is the key to the confusion matrix. The confusion matrix shows the ways in which your classification model is confused when it makes predictions. It gives us insight not only into the errors being made by a classifier but, more importantly, the types of errors that are being made.\n",
    "\n",
    "![](matrix.png)\n",
    "\n",
    "- The *AUC score*  provides an aggregate measure of performance across all possible classification thresholds. One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example. \n",
    "\n",
    "Run the code cell below to visualise the performance of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, auc\n",
    "print('Decision Tree Model - reservation_status included')\n",
    "\n",
    "print('Accuracy Score: {}\\n\\nConfusion Matrix:\\n {}\\n\\nAUC Score: {}'\n",
    "      .format(accuracy_score(y_test,y_pred_cart), confusion_matrix(y_test,y_pred_cart), roc_auc_score(y_test,y_pred_cart)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could you say why this model is doing so well?\n",
    "\n",
    "**DOUBLE CLICK ON THIS CELL TO TYPE YOUR ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, use the function `drop()` to eliminate the columns `reservation_status_Canceled`, `reservation_status_Check-Out`, `reservation_status_No-Show` from `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bofore going ahead, we need to split our dataframe into an `X` and a `y` set again in the same way as we did Part 5.\n",
    "\n",
    "Complete the code cell below to achieve so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \n",
    "X = \n",
    "X_train, X_test, y_train, y_test = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part7'></a>\n",
    "\n",
    "### Part 7 - Decision tree model (reservation_status excluded)\n",
    "    \n",
    "In this part, we will recompute the performance of the decision tree model after excluding the reservation status feature.\n",
    "    \n",
    "Complete the code cell below to instantiate the class as `dt`. Again, we'll use `max_depth = 12`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, use the `fit()` method to train the model on the training `X` and `y` sets.\n",
    "\n",
    "Finally, predict the test set results from the trained `dt_model` object using `X_test` and save them to `y_pred_dt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = \n",
    "y_pred_dt ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the code syntax we used in Part 6, complete the print statement in the code cell below to print the accuracy score, the confusion matrix, and the  AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Decision Tree Model - reservation_status excluded')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did this model perform compared to the one used in Part 6?\n",
    "\n",
    "**DOUBLE CLICK ON THIS CELL TO TYPE YOUR ANSWER**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part8'></a>\n",
    "\n",
    "### Part 8 -  K-nearest neighbours\n",
    "    \n",
    "The  K-nearest neighbours algorithm is an easy, straight-forward algorithm that's easy to implement using Python. It simply works by calculating the distance between new data points and classifying them based on how close it is to existing, labeled data from the training see. Thus, it's considered a _lazy_ algorithm.\n",
    "\n",
    " K-nearest neighbours only requires that you specify two parameters in `scikit-learn` -- the value of K (the number of neighbors, `n_neighbors` in Python), and the distance metric used (i.e., Euclidean distance or Manhattan distance, specified by the parameter `p`).\n",
    "\n",
    "In the code cell below, import the `KNeighborsClassifier` class from `sklearn.neighbors` and instantiate the class as `knn`. We'll use `n_neighbors = 10` and `p = 1` to represent the Manhattan distance algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  import \n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, use the `fit()` method to train the model on the training `X` and `y` sets.\n",
    "\n",
    "Finally, predict the test set results from the trained `knn_model` object using `X_test` and save them to `y_pred_knn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = \n",
    "y_pred_knn ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the code syntax we used in Part 7, complete the print statement in the code cell below to print the accuracy score, the confusion matrix and the  AUC score to screen for the  K-nearest neighbours algorithmn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('K-Nearest Neighbors')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the values of the confusion matrix above compare to the ones obtained in Part 7? What can you infer from this?\n",
    "\n",
    "**DOUBLE CLICK ON THIS CELL TO TYPE YOUR ANSWER**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part9'></a>\n",
    "\n",
    "### Part 9 - Naïve Bayes\n",
    "    \n",
    " Naïve Bayes is a classification technique based on Bayes’ theorem with an assumption of independence among predictors. \n",
    "\n",
    "In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. \n",
    "\n",
    "\n",
    "In the code cell below, import the `GaussianNB` class from `sklearn.naive_bayes` and instantiate the class as `nb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  import \n",
    "nb  =  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, use the `fit()` method to train the model on the training `X` and `y` sets.\n",
    "\n",
    "Finally, predict the test set results from the trained `nb_model` object using `X_test` and save them to `y_pred_nv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = \n",
    "y_pred_nb ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the code syntax we used in Part 7, complete the print statement in the code cell below to print the accuracy score, the confusion matrix and the  AUC score to screen for the Naïve Bayes algorithmn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Naïve Bayes')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did the Naïve Bayes classifier perform poorly compared to other models?\n",
    "\n",
    "**DOUBLE CLICK ON THIS CELL TO TYPE YOUR ANSWER**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part10'></a>\n",
    "\n",
    "### Part 10 - Conclusion\n",
    "    \n",
    "Based on all the results obtained above, which algorithmn seems to make the most accurate prediction?\n",
    "\n",
    "**DOUBLE CLICK ON THIS CELL TO TYPE YOUR ANSWER**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on all the results obtained above, which algorithm seems to make the least accurate prediction?\n",
    "\n",
    "**DOUBLE CLICK ON THIS CELL TO TYPE YOUR ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONGRATULATIONS ON COMPLETING THE FINAL ASSIGNMENT!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
