{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 9, Classification and Regression Trees\n",
    "\n",
    "**_Author: Jessica Cervi_**\n",
    "\n",
    "**Expected time = 2 hours**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "## Assignment overview\n",
    "\n",
    "Decision trees are a non-parametric supervised learning method used for classification and regression. Decision trees learn from data to approximate a curve with a set of if-then-else decision rules. The deeper the tree, the more complex the decision rules and the fitter the model.\n",
    "Decision trees build classification or regression models in the form of trees. They break down a data set into smaller and smaller subsets while incrementally developing the associated decision tree. The final result is a tree with decision nodes and leaf nodes. A decision node has two or more branches. Leaf nodes represent a classification or decision. The topmost decision node in a tree, which corresponds to the best predictor, is called the root node. \n",
    "\n",
    "\n",
    "\n",
    "This assignment is designed to help you apply the machine learning algorithms you have learnt using packages in Python. Python concepts, instructions, and starter code are embedded within this Jupyter Notebook to help guide you as you progress through the assignment. Remember to run the code of each code cell prior to submitting the assignment. Upon completing the assignment, we encourage you to compare your work against the solution file to perform a self-assessment.\n",
    "\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "\n",
    "- Discuss the difference between conducting splits on categorical and numerical input variables\n",
    "- Demonstrate how to measure purity in categorical models using entropy and the Gini index\n",
    "- Compare strategies for pruning a classification tree\n",
    "- Explain the differences between classification and regression trees\n",
    "- Use bagging to move from a single tree to an ensemble of trees\n",
    "- Outline two algorithms for de-correlating decision trees\n",
    "- Share real-life applications of decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index:\n",
    "\n",
    "#### Week 9:   Classification and regression trees\n",
    "\n",
    "\n",
    "- [Part 1](#part1)- Importing the data set and exploratory data analysis (EDA)\n",
    "- [Part 2](#part2)- Translate the categorical predictors into numerical predictors\n",
    "- [Part 3](#part3)- Shuffle the data set\n",
    "- [Part 4](#part4)- Calculate the accuracy of the Naïve benchmark on the validation set.\n",
    "- [Part 5](#part5)- Train a decision tree using the default settings\n",
    "- [Part 6](#part6)- Train a decision tree using different maximum depths for the tree\n",
    "- [Part 7](#part7)- Retrain the best classifier using all the samples\n",
    "\n",
    "\n",
    "\n",
    "## Classification and regression trees\n",
    "\n",
    "In Week 9, you learnt about classification using regression trees.\n",
    "The basic idea behind the algorithm for classification via regression trees can be summarised as follows:\n",
    "\n",
    "- Load the data set\n",
    "- Select the best attribute using Attribute Selection Measures (ASM) to split the records.\n",
    "- Make that attribute a decision node and break the data set into smaller subsets.\n",
    "- Start bulding the tree by repeating this process recursively for each child until one of the conditions will match:\n",
    "    - All the tuples belong to the same attribute value.\n",
    "    - There are no more remaining attributes.\n",
    "    - There are no more instances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict defaults for student loans applications\n",
    "\n",
    "For this exercise, we will use the data set `loandata.xlsx` to predict defaults for student loans applications using regression trees. We will perform the following steps:\n",
    "\n",
    "1. Load the data set `loandata.xlsx` into Python.\n",
    "2. Translate the categorical predictors into numerical predictors. \n",
    "3. Shuffle the data set and split it into 50% training data, 25% validation data and 25% test data.\n",
    "4. Calculate the accuracy of the Naïve benchmark  on the validation set.\n",
    "5. Train a decision tree using the default settings.\n",
    "6. Retry the previous step using different maximum depths for the tree. \n",
    "7. Choose the most appropriate tree depth and justify your choice. Re-train the best classifier using all the samples from both the training and the validation set. Retrain the best classifier on all samples (including the test set) and describe the tree that you obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part1'></a>\n",
    "\n",
    "### Part 1 -  Importing the data set and exploratory data analysis (EDA)\n",
    "\n",
    "We begin by importing the necessary libraries. We will then use `pandas` to import the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree, ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this week's datacset is in `.xlsx` format.\n",
    "\n",
    "Complete the code cell below by adding the name of the data set as a `str` to `.read_excel()`. Assign the dataframe to the variable `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Before building any machine learning algorithms, we should explore the data.\n",
    "\n",
    "We begin by visualising the first ten rows of the dataframe `df` using the function `.head()`. By default, `.head()` displays the first five rows of a dataframe.\n",
    "\n",
    "Complete the code cell below by passing the desired number of rows as an `int` to the function `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.head( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your convenience, here is a brief description of what some of the columns represent:\n",
    "    \n",
    "- field: the field in which each student is taking their studies in\n",
    "- graduationYear: the year in which each student graduated\n",
    "- loanAmount: the amount each student owns\n",
    "- selective College: binary valued column: 1 for students who attend a selective college, 0 for students that do not\n",
    "- sex: sex of the student\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part2'></a>\n",
    "\n",
    "### Part 2 -  Translate the categorical predictors into numerical predictors\n",
    "\n",
    "How do we handle categorical features?\n",
    "\n",
    "In most of the well-established machine learning systems, categorical variables are handled naturally. However, when dealing with decision trees using `scikit-learn`, we need to encode (translate) categorical features into numerical features.\n",
    "\n",
    "Arguably, the easiest way to achieve this is by using the `pandas` function `get_dummies()` that converts categorical variables into dummy/indicator variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the dataframe `df` above. Which columns do you think are affected by the `get_dummies()` function?\n",
    "\n",
    "**TYPE YOUR ANSWER BY DOUBLE CLICKING ON THIS CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code cell below by using the function on the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode categorical variables \n",
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are only interested in the students that will apply for a student loan,  we will only need to keep the column `Default_Yes`.\n",
    "\n",
    "Complete the code cell below by using the function `.drop()` on `df` to eliminate the *column* `Default_no`. The `axis` parameter in `.drop()` controls whether the function acts on rows or columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Default_No\n",
    "#df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to visualise the new dataframe with the encoded columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part3'></a> \n",
    "\n",
    "### Part 3 - Shuffle the data set\n",
    "\n",
    "Now, we want to shuffle the data: one way of doing this is by converting our dataframe to a `NumPy` array and then using the `.shuffle()` function to achieve this. Run the code cell below to convert the `df` into a `NumPy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy=np.array(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reproducibility, set the random seed = 2. You can do this by using the `NumPy` function `random.seed()`. Assign your seed to the variable `seed`. Next, complete the code cell below by using the function `random.shuffle()` on `Xy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.seed(2)\n",
    "np.random.shuffle(Xy)\n",
    "\n",
    "#seed = \n",
    "#shuffle\n",
    "#np."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before splitting the data into a training set, a test set, and a validation set, we need to divide `Xy` into two arrays: the first one, `X`, a 2D array containing all the predictors and the second, `y`, is a 1D array with the response. \n",
    "\n",
    "Run the code cell below to generate `X`. Complete the remaining code to define `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Xy[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define y\n",
    "y= "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we need to split into sets with certain dimensions according to the instructions given above, it would be useful to know how big our `X` and `y` are.\n",
    "\n",
    "Run the code cell below to retrieve this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to split the messages into into 50% training data, 25% validation data, and 25% test data.\n",
    "\n",
    "Run the code below to split `X` into training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsize = 1000\n",
    "trainplusvalsize = 500\n",
    "X_train=X[:trainsize]\n",
    "X_val=X[trainsize:trainsize + trainplusvalsize]\n",
    "X_test=X[trainsize + trainplusvalsize:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the syntax used above, complete the cell below to split `y` into training set, a validation set, and a test set.\n",
    "\n",
    "**HINT:** Remember that `y` is a 1D array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=\n",
    "y_val=\n",
    "y_test=\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part4'></a>\n",
    "\n",
    "### Part 4 - Calculate the accuracy of the Naïve benchmark on the validation set\n",
    "\n",
    "In this part, we want to calculate the accuracy of the Naïve benchmarch on both the `y` training and validation sets. In other words, we want to understand how accurate our predictions would be if we assumed that no one defaulted on their student loans.\n",
    "\n",
    "Accuracy can be computed by comparing actual test set values and predicted values. In this example, the formulae to compute accuracy are:\n",
    "\n",
    "$$ \\text{acc_train} = 1 - \\frac{\\sum{\\text{y_train}}}{\\text{len(y_train)}},$$\n",
    "\n",
    "$$ \\text{acc_val} = 1 - \\frac{\\sum{\\text{y_val}}}{\\text{len(y_val)}}.$$\n",
    "\n",
    "Note that $\\frac{\\sum{\\text{y_train}}}{\\text{len(y_train)}}$ reflects the proportion of students who defaulted on their loan in the training set, and $\\frac{\\sum{\\text{y_val}}}{\\text{len(y_val)}}$ reflects the proportion of students who defaulted on their loan in the validation set.\n",
    "\n",
    "Compute the required accuracy in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = \n",
    "acc_val = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to print the results to screen. What can you say about the baseline accuracy if we predict that no students defaulted (i.e., everyone belongs to the majority class)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( 'Naïve guess train and validation', acc_train , acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part5'></a>\n",
    "\n",
    "### Part 5 - Train a decision tree using the default settings\n",
    "\n",
    "The easiest way to create a decision tree model is by using the function `DecisionTreeClassifier()`. This function is part of the `tree` module of `Scikit-learn` (`sklearn`).\n",
    "\n",
    "As we will see, there are ways to improve the accuracy of our tree. For now, let's build a classifier using the default settings.\n",
    "\n",
    "In the code cell below, use `DecisionTreeClassifier()` to define a classifier `clf` . Next, use the method `fit()` of your classifier to fit your training sets, `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf =\n",
    "#Fit X_train and y_train \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to visualise the new scores on the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( 'Full tree guess train/validation ',clf.score(X_train, y_train),clf.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results obtained so far, what do you think of this classifier?\n",
    "\n",
    "**TYPE YOUR ANSWER BY DOUBLE CLICKING ON THIS CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part6'></a>\n",
    "\n",
    "### Part 6 - Train a decision tree using  different maximum depths for the tree\n",
    "\n",
    "One way we can optimise the decision tree algorithm is by adjusting the maximum depth of the tree. This process is an example of pre-pruning. \n",
    "\n",
    "In the following example, we will compute the score for  a decision tree on the same data with `max_depth = 15`.\n",
    "\n",
    "We begin by defining the variables `bestdepth` and `bestscore`, assuming the *worst case scenario*. Run the code cell below to inizialise the variable as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestdepth=-1\n",
    "bestscore=0\n",
    "max_depth = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will write a for loop to progressively compute the new training/validation scores for different depths.\n",
    "\n",
    "Here is the pseudocode for the for loop you will need to implement:\n",
    "\n",
    "```python\n",
    "\n",
    "for i in range(max_depth):\n",
    "    # compute new classifier clf with depth = max_depth = i+1\n",
    "    # fit the X and y training sets with the new classifier\n",
    "    # compute the updated trainscore using .score() on the training set \n",
    "    # compute the updated valscore using .score() on the validation set\n",
    "    # print the scores\n",
    "    print ( 'Depth:', i+1, 'Training Score:', trainscore, 'Validation Score:', valscore)\n",
    "     \n",
    "    # if valscore is better than bestscore:\n",
    "        # update the value of bestscore\n",
    "        # increase bestdepth by one unit\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    clf = \n",
    "    #fit the training sets\n",
    "    clf.fit( )\n",
    "    #update trainscore\n",
    "    trainscore=\n",
    "    #update valscore\n",
    "    valscore=\n",
    "    print( 'Depth:', i+1, 'Train Score:', trainscore, 'Validation Score:', valscore)\n",
    "    if    :\n",
    "        #update bestscore\n",
    "        bestscore=\n",
    "        #update depth\n",
    "        bestdepth="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the most appropriate tree depth and justify your choice.\n",
    "\n",
    "**TYPE YOUR ANSWER BY DOUBLE CLICKING ON THIS CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part7'></a>\n",
    "\n",
    "### Part 7 - Retrain the best classifier using all the samples\n",
    "\n",
    "For the last part of this assignment, retrain the best classifier using all the samples from the training and the validation sets *together*. \n",
    "\n",
    "We begin by re-defining our `X_trainval` and `y_trainval`. Below, we have defined `X_trainval` for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval=X[:trainplusvalsize,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the syntax given above, define `y_trainval`.\n",
    "\n",
    "Again, remember that `y` is a 1D array! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainval = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To re-train the sets using the best classifier, re-define `clf`  using `DecisionTreeClassifier()` with `max_depth` equal to the `bestdepth` computed in Part 6. Next, fit the classifiers to the sets just defined above.\n",
    "\n",
    "Complete the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = \n",
    "#fitX_trainval and y_trainval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, re-train the best classifier on all samples (including the test set).\n",
    "\n",
    "Do so by using the function `score()` to compute the score on both the test sets. Assign the result to `test_score`.\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('testing set score', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " What do you observe?\n",
    "\n",
    "**TYPE YOUR ANSWER BY DOUBLE-CLICKING ON THIS CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONGRATULATIONS ON COMPLETING THE WEEK 9 ASSIGNMENT!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
